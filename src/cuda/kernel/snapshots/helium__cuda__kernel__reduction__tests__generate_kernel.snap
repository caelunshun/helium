---
source: src/cuda/kernel/reduction.rs
expression: kernel.code
---
#include <cuda_fp16.h>
#include <cuda_bf16.h>
#include <cuda_runtime.h>
#include <math_constants.h>

typedef unsigned int uint32_t;

__device__ __forceinline__ float atomicMinFloat (float *addr, float value) {
    float old;
    old = (value >= 0) ? __int_as_float(atomicMin((int *)addr, __float_as_int(value))) :
        __uint_as_float(atomicMax((unsigned int *)addr, __float_as_uint(value)));

    return old;
}

__device__ __forceinline__ float atomicMaxFloat(float *addr, float value) {
    float old;
    old = (value >= 0) ? __int_as_float(atomicMax((int *)addr, __float_as_int(value))) :
        __uint_as_float(atomicMin((unsigned int *)addr, __float_as_uint(value)));

    return old;
}

extern "C" __global__ void generatedReductionKernel(half *ident0, nv_bfloat16 *ident2, float ident4, half *ident7, float *reductionOut,  uint32_t stride, uint32_t totalSize) {
    extern __shared__ float localReduction[];

    uint32_t totalIndex = threadIdx.x + blockDim.x * blockIdx.x;
    uint32_t strideRoundedUp = (stride + blockDim.x - 1) / blockDim.x * blockDim.x;

    uint32_t group = totalIndex / strideRoundedUp;
    uint32_t indexInGroup = totalIndex % strideRoundedUp;
    
    float val = 0.0;
    if (indexInGroup < stride) {
        uint32_t index = group * stride + indexInGroup;
        float ident1 = ident0[index];
float ident3 = ident2[index];
float ident5 = ident1 * ident4;
float ident6 = ident5 + ident3;
ident7[index] = static_cast<half>(ident6);
float scaledVal = ident6 / stride;

        val = scaledVal;
    }

    // Block-level reduction
    for (int offset = blockDim.x / 2; offset >= 32; offset /= 2) {
        localReduction[threadIdx.x] = val;
        __syncthreads();
        if (threadIdx.x < offset) {
            int target = threadIdx.x + offset;
            val = val + localReduction[target];
        }
    }

    // Warp-level reduction
    __syncthreads();
    if (threadIdx.x < 32) {
        uint32_t mask = 0xFFFFFFFF;
        for (int offset = 16; offset > 0; offset /= 2) {
            float otherWarpVal = __shfl_down_sync(mask, val, offset);
            val = val + otherWarpVal;
        }

        // Grid-level reduction
        if (threadIdx.x == 0) {
            atomicAdd(reductionOut + group, val);
        }
    }
}
